{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word-Level Language Modeling\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get all files name under path\n",
    "\n",
    "Args:\n",
    "    path: folder path to retrieve files' name.\n",
    "    ratio: propotion of training data. Default value is 1 (100%).\n",
    "    shuffle: a boolean value. TRUE: shuffle list; False: order list.\n",
    "\n",
    "Returns:\n",
    "    filesName[:train]: a list of all files end with \".txt\" for training set. For example:\n",
    "\n",
    "    [\"dir/a.txt\", \"dir/b.txt\"].\n",
    "\n",
    "    filesName[train:]: a list of all files end with \".txt\" for held-out set. For example:\n",
    "\n",
    "    [\"dir/a.txt\", \"dir/b.txt\"].\n",
    "\"\"\"\n",
    "def getFilesName( path, ratio = 1, shuffle = False ):\n",
    "    print( \"Retrieving files name from folder %s...\" % ( path ) )\n",
    "    filesName = []\n",
    "    files = os.listdir( path )\n",
    "    for file in files:\n",
    "        name = '/'.join( [path, file] )\n",
    "        filesName.append( name )\n",
    "    if shuffle:\n",
    "        random.shuffle( filesName )\n",
    "    else:\n",
    "        filesName.sort()\n",
    "    total = len( filesName )\n",
    "    train = int( total * ratio )\n",
    "    return filesName[:train], filesName[train:]\n",
    "\n",
    "\"\"\"Preprocess data\n",
    "\n",
    "Find words in training set that appear ≤ 5 times as “UNK”.\n",
    "\n",
    "Note: The function will figure out all words which are need to be replaced by \"UNK\"\n",
    "      and they will be replaced when building n-gram word-level language model.\n",
    "\n",
    "Args:\n",
    "    contents: a list of content to be processed. Content is also a list.\n",
    "\n",
    "Returns:\n",
    "    repc: a list of words that need to be replaced with \"<UNK>\". For example:\n",
    "    \n",
    "    \"[word a, word b, word c]\"\n",
    "\"\"\"\n",
    "def unk( contents ):\n",
    "    d = {}\n",
    "    for content in contents:\n",
    "        for w in content:\n",
    "            if w not in d:\n",
    "                d[w] = 0\n",
    "            d[w] += 1\n",
    "    repw = {}\n",
    "    for ( k, v ) in d.items():\n",
    "        if v <= 3:\n",
    "            if k not in repw:\n",
    "                repw[k] = 0\n",
    "            repw[k] += 1\n",
    "    return repw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Word-Level Language Model\n",
    "\"\"\"Generate n-gram dictionary.\n",
    "\n",
    "Generate n-gram dictionary based on fed string and n.\n",
    "\n",
    "Args:\n",
    "    contents: a list of content used to calculate ngrams.\n",
    "    n: n-gram.\n",
    "    d: language model corresponds to n-gram.\n",
    "\n",
    "Returns:\n",
    "    None.\n",
    "\"\"\"\n",
    "def ngrams( contents, n, d ):\n",
    "    for content in contents:\n",
    "        for i in range( n - 1, len( content ) - 1 ):\n",
    "            k = ' '.join( content[i - n + 1:i + 1] )\n",
    "            if k not in d[\"c\"]:\n",
    "                d[\"c\"][k] = 0\n",
    "            d[\"c\"][k] += 1\n",
    "            d[\"t\"] += 1\n",
    "\n",
    "\"\"\"Build language model\n",
    "\n",
    "Preprocess files and across all files in the directory (counted together), report the \n",
    "unigram, bigram, and trigram words counts.\n",
    "\n",
    "Args:\n",
    "    content: a list contains content needed to be processed.\n",
    "\n",
    "Returns:\n",
    "    lm: a dictionary of language model when savePath equals empty string. Its structure is:\n",
    "    \n",
    "    {\"unigram\": {\"c\": unigram, \"t\": total unigram words},\n",
    "     \"bigram\" : {\"c\": bigram,  \"t\": total bigram  words},\n",
    "     \"trigram\": {\"c\": trigram, \"t\": total trigram words}}.\n",
    "\"\"\"\n",
    "def LM( contents ):\n",
    "    print( \"Building language modeling...\" )\n",
    "    lm = {\"unigram\": {\"c\": {}, \"t\": 0},\n",
    "          \"bigram\" : {\"c\": {}, \"t\": 0},\n",
    "          \"trigram\": {\"c\": {}, \"t\": 0}}\n",
    "    ngram = [\"unigram\", \"bigram\", \"trigram\"]\n",
    "    \n",
    "    # Calculate unigram, bigram, and trigram\n",
    "    print( \"Calculating n-grams...\" )\n",
    "    ngrams( contents, 1, lm[\"unigram\"] )\n",
    "    ngrams( contents, 2, lm[\"bigram\" ] )\n",
    "    ngrams( contents, 3, lm[\"trigram\"] )\n",
    "    return lm\n",
    "\n",
    "\"\"\"Build Language Model\n",
    "\n",
    "Across all files in the directory (counted together), report the unigram, bigram, and trigram\n",
    "words counts and save them in seperate files.\n",
    "\n",
    "Args:\n",
    "    trainDataPath: train data path.\n",
    "    encoding: train data files' encoding\n",
    "    savePath: path to save language model.\n",
    "    ratio: the proportion of the real training set comparing to whole training set\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\"\"\"\n",
    "def buildLM( trainDataPath = \"./train\", encoding = \"Latin-1\", savePath = \"./lm\", ratio = 1 ):\n",
    "    ngram = [\"unigram\", \"bigram\", \"trigram\"]\n",
    "    trainFiles, heldOutFiles = getFilesName( trainDataPath )\n",
    "    # preprocess data and find UNK\n",
    "    print( \"Counting for finding UNK.\")\n",
    "    contents = []\n",
    "    for fileName in trainFiles:\n",
    "        with open( fileName, 'r', encoding = encoding ) as f:\n",
    "            content = []\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                contents.append( line.split() )\n",
    "                line = f.readline()\n",
    "    repw = unk( contents )\n",
    "    if len( repw ):\n",
    "        for content in contents:\n",
    "            for i in range( len( content ) ):\n",
    "                if content[i] in repw:\n",
    "                    content[i] = \"<UNK>\"\n",
    "    lm = LM( contents )\n",
    "    if not os.path.isdir( savePath ):\n",
    "        os.makedirs( savePath )\n",
    "    for name in ngram:\n",
    "        print( name )\n",
    "        with open( savePath + \"/\" + name, \"w\", encoding = encoding ) as f:\n",
    "            f.write( str( lm[name][\"t\"] ) + \"\\n\" )\n",
    "            for ( k, v ) in lm[name][\"c\"].items():\n",
    "                f.write( k + \" \" + str( v ) + \"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "def test():\n",
    "    # Build Word-Level Language Model\n",
    "    print( \"Building Word-Level Language Model...\" )\n",
    "    buildLM( trainDataPath = \"../Data/train/english\", encoding = \"UTF-8\", savePath = \"./lm\" )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    groupsmoothing = parser.add_mutually_exclusive_group()\n",
    "    groupsmoothing.add_argument( \"-t\", \"--test\", help = \"Test on all funcitions\", action=\"store_true\" )\n",
    "    groupsmoothing.add_argument( \"-b\", \"--build\", help = \"Build a Word-level n-gram language model\", \n",
    "                                 action=\"store_true\" )\n",
    "    parser.add_argument( \"-e\", \"--encoding\", type = str,\n",
    "                         help = \"Encoding of files\", default = \"Latin-1\" )\n",
    "    parser.add_argument( \"-r\", \"--ratio\", type = float,\n",
    "                         help = \"proportion of real train data files in train data path\",\n",
    "                         default = 1.0 )\n",
    "    parser.add_argument( \"--trainPath\", type = str, help = \"Path that train data stores\",\n",
    "                         default = \"./train\" )\n",
    "    parser.add_argument( \"--savePath\",  type = str, help = \"Path that function result will save at\",\n",
    "                         default = \"./save\" )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.test:\n",
    "        test()\n",
    "    if args.build:\n",
    "        buildLM( args.trainPath, args.encoding, args.savePath, args.ratio )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
