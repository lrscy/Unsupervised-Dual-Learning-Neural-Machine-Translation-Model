{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Abstract\n",
    "\n",
    "The demo is a prototype of the project model. Codes here could change in the future.\n",
    "The main point of codes below is to run on local computer and test whether it works on small scale of data.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from elmoformanylangs import Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Simple Seqence to Sequence Implementation\n",
    "\n",
    "A simple implementation of Sequence to Sequence model. It works as baseline\n",
    "\n",
    "Args:\n",
    "    input_dim:  dimension of input word vector.\n",
    "    output_dim: dimension of output word vector.\n",
    "    hidden_dim: dimension of hidden states vector.\n",
    "\n",
    "Returns:\n",
    "    model: the whole model of simple Seq2Seq model.\n",
    "\n",
    "\"\"\"\n",
    "def simpleSeq2Seq( output_dim = 1024, input_dim = 1024, hidden_dim = 512, name = \"\" ):\n",
    "    # Encoder\n",
    "    encoder_input = Input( shape = ( None, input_dim ), name = \"encoder_input\" )\n",
    "    encoder_output, state_h, state_c = LSTM( hidden_dim, return_state = True )( ori_input )\n",
    "    state_encoder = [state_h, state_c]\n",
    "    # Decoder\n",
    "    decoder_input = Input( shape = ( None, output_dim ), name = \"decoder_input\" )\n",
    "    decoder_outputs = LSTM( hidden_dim, return_sequences = True )( decoder_input, initial_state = state_encoder )\n",
    "    decoder_outputs = Dense( output_dim, activation = \"softmax\", name = \"decoder_output\" )( decoder_outputs )\n",
    "    model = Model( Input[encoder_input, decoder_input], output = decoder_outputs, name = name )\n",
    "    return model\n",
    "\n",
    "def model( langA_dim = 1024, langB_dim = 1024, hidden_dim = 512, lmA, lmB ):\n",
    "    # first part of translation model from language A to language B\n",
    "    langA_input  = Input( shape = ( None, langA_dim ), name = \"langA_input\"  )\n",
    "    langB_output = Input( shape = ( None, langB_dim ), name = \"langB_output\" )\n",
    "    A2B_model = simpleSeq2Seq( langB_dim, langA_dim, hidden_dim, name = \"A2B\" )\n",
    "    langB_output = A2B_model( [langA_input, langB_output] )\n",
    "    # language model <- langB_output\n",
    "    # second part of translation model from another language to original language\n",
    "    langB_input  = Input( shape = ( None, langB_dim ), name = \"langB_input\"  )\n",
    "    langA_output = Input( shape = ( None, langA_dim ), name = \"langA_output\" )\n",
    "    B2A_model = simpleSeq2Seq( langA_dim, langB_dim, hidden_dim, name = \"B2A\" )\n",
    "    langA_output = B2A_model( [langB_input, langA_output] )\n",
    "    # language model <- langA_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
